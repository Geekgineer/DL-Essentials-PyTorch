{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292d68f7",
   "metadata": {},
   "source": [
    "### ðŸš€ Open in Google Colab\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Geekgineer/DL-Essentials-PyTorch/blob/main/1-Data-Manipulation-with-PyTorch/Data-Manipulation-with-PyTorch.ipynb\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93340934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DL-Essentials-PyTorch'...\n",
      "remote: Enumerating objects: 6, done.\u001b[K\n",
      "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 6 (delta 0), reused 5 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (6/6), done.\n",
      "remote: Enumerating objects: 2, done.\u001b[K\n",
      "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
      "remote: Total 2 (delta 0), reused 2 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (2/2), 81 bytes | 81.00 KiB/s, done.\n",
      "/home/amer/Desktop/OBS/data/Mastring-PyTorch/Ø£Ø³Ø§Ø³ÙŠØ§Øª Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª ÙˆØ§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyTorch | Deep Learning Essentials with PyTorch\n",
      "/1-Data-Manipulation-with-PyTorch/DL-Essentials-PyTorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amer/Downloads/yes/envs/torch/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 9, done.\u001b[K\n",
      "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
      "remote: Total 9 (delta 0), reused 9 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (9/9), 1.54 MiB | 1.80 MiB/s, done.\n",
      "Updating files: 100% (12/12), done.\n",
      "/home/amer/Desktop/OBS/data/Mastring-PyTorch/Ø£Ø³Ø§Ø³ÙŠØ§Øª Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª ÙˆØ§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyTorch | Deep Learning Essentials with PyTorch\n",
      "/1-Data-Manipulation-with-PyTorch/DL-Essentials-PyTorch/1-Data-Manipulation-with-PyTorch\n",
      "broadcastplot.py  Data-Manipulation-with-PyTorch.ipynb\timgs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List of required files\n",
    "file_urls = [\n",
    "    \"https://raw.githubusercontent.com/Geekgineer/DL-Essentials-PyTorch/main/1-Data-Manipulation-with-PyTorch/Data_Manipulation.ipynb\",\n",
    "    \"https://raw.githubusercontent.com/Geekgineer/DL-Essentials-PyTorch/main/1-Data-Manipulation-with-PyTorch/utils.py\"\n",
    "]\n",
    "\n",
    "# Download each file\n",
    "for url in file_urls:\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        os.system(f\"wget -q {url}\")\n",
    "\n",
    "# Verify downloaded files\n",
    "!ls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cuINhVsCbMvj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3336,
     "status": "ok",
     "timestamp": 1727004069609,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "cuINhVsCbMvj",
    "outputId": "0a8aa0a0-5e63-46a5-b090-5b4e7e617617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive/Colab Notebooks/DeepLearningEssentials')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y2zRNGmhj6yI",
   "metadata": {
    "id": "y2zRNGmhj6yI"
   },
   "source": [
    "# Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XXfbgr9AKrHl",
   "metadata": {
    "id": "XXfbgr9AKrHl"
   },
   "source": [
    "<img src=\"https://github.com/user-attachments/assets/29a6f82d-4084-4964-8964-cd851f55d567\" alt=\"Overall Image\" width=\"800\" height=\"500\">\n",
    "\n",
    "\n",
    "1. **Deep Learning Revolution**:\n",
    "   - Automates feature extraction that traditionally required manual engineering.\n",
    "   - Uses large datasets to train models that approximate complex functions.\n",
    "\n",
    "2. **PyTorch's Flexibility and Ease of Use**:\n",
    "   - Praised for its simplicity and Pythonic nature.\n",
    "   - Supports accelerated computation on GPUs, ideal for deep learning projects.\n",
    "\n",
    "3. **Building Blocks of PyTorch**:\n",
    "   - **Tensors**: For multidimensional arrays.\n",
    "   - **Autograd Engine**: For automatic differentiation, essential for training neural networks.\n",
    "\n",
    "4. **Training and Deployment**:\n",
    "   - Supports the full cycle: data loading, training, and deployment.\n",
    "   - Tools: TorchScript for deployment and ONNX format for exporting models.\n",
    "\n",
    "5. **Hardware and Software Requirements**:\n",
    "   - Basic tasks can be performed on standard hardware.\n",
    "   - Advanced projects benefit from a CUDA-capable GPU for faster training.\n",
    "\n",
    "6. **Evolution of Deep Learning Libraries**:\n",
    "   - Consolidation in the deep learning landscape.\n",
    "   - PyTorch and TensorFlow are the dominant libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de623d7",
   "metadata": {
    "id": "0de623d7",
    "origin_pos": 1
   },
   "source": [
    "# Data Manipulation with Tensors\n",
    "\n",
    "Purpose of Data Manipulation\n",
    "1. **Acquisition**: Gathering data from various sources.\n",
    "2. **Processing**: Performing operations and transformations on data inside the computer.\n",
    "\n",
    "Tensors: n-Dimensional Arrays\n",
    "- **Definition**: Fundamental data structure for storing and manipulating data.\n",
    "- **Similarity to NumPy**: Tensors resemble NumPy's `ndarray` but with additional features.\n",
    "\n",
    "Features of Tensor Classes\n",
    "- **Automatic Differentiation**: Facilitates gradient computation for optimization, crucial for training neural networks.\n",
    "- **GPU Acceleration**: Speeds up numerical computations by utilizing GPUs, unlike NumPy which is CPU-based.\n",
    "\n",
    "Advantages\n",
    "- **Ease of Coding**: Simplifies the implementation of neural network operations.\n",
    "- **Efficiency**: Enhances performance by leveraging hardware acceleration.\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/7e7c6a12-4f14-49c8-b81f-3971a36fc3e8\" alt=\"worldasfb Image\" width=\"800\" height=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ju4x0QaDsSuf",
   "metadata": {
    "id": "ju4x0QaDsSuf"
   },
   "source": [
    "Floating-Point Numbers\n",
    "- **Encoding and Decoding**: Converting real-world data into a format digestible by neural networks and decoding output back to usable information.\n",
    "- **Intermediate Representations**: Sequences of floating-point numbers that capture data characteristics at various stages of transformation.\n",
    "\n",
    "PyTorch Tensors\n",
    "- **Definition**: Generalization of vectors and matrices to multiple dimensions (multidimensional arrays).\n",
    "- **Comparison with NumPy**: PyTorch tensors offer advantages such as GPU acceleration and efficient computation across devices.\n",
    "\n",
    "Key Concepts\n",
    "- **Tensor Basics**: Fundamental structure for storing and manipulating data in PyTorch.\n",
    "- **Capabilities**: Includes fast operations, GPU support, and integration with NumPy and other scientific libraries.\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/1caf174f-805d-4480-824a-3626aa1ebc73\" alt=\"tensors Image\" width=\"800\" height=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084dc517",
   "metadata": {
    "id": "084dc517",
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "(**To start, we import the PyTorch library.\n",
    "Note that the package name is `torch`.**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01fa8e58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:55.152236Z",
     "iopub.status.busy": "2023-08-18T19:32:55.151500Z",
     "iopub.status.idle": "2023-08-18T19:32:57.051589Z",
     "shell.execute_reply": "2023-08-18T19:32:57.050409Z"
    },
    "executionInfo": {
     "elapsed": 100,
     "status": "ok",
     "timestamp": 1727004071785,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "01fa8e58",
    "origin_pos": 6,
    "outputId": "86300963-3c12-4c42-d97f-7382259b382e",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.4.1+cu121'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y2UgUBKGf4kA",
   "metadata": {
    "id": "Y2UgUBKGf4kA"
   },
   "source": [
    "**The Essence of Tensors**\n",
    "\n",
    "- **Python Lists vs. Tensors**:\n",
    "  - Python lists or tuples of numbers store individual Python objects, each with its own memory allocation.\n",
    "  - PyTorch tensors or NumPy arrays, in contrast, are views over contiguous memory blocks with unboxed C numeric types, making them more memory efficient.\n",
    "\n",
    "- **Memory Efficiency**:\n",
    "  - For example, a 1D tensor with 1,000,000 float numbers requires exactly 4,000,000 bytes plus a small overhead for metadata.\n",
    "\n",
    "- **Creating Tensors**:\n",
    "  - A tensor can be initialized using `torch.zeros()` to create an appropriately sized array, which can then be filled with specific values.\n",
    "  - Alternatively, tensors can be directly created from Python lists using `torch.tensor()`.\n",
    "\n",
    "- **Tensor Operations**:\n",
    "  - Accessing elements in a tensor can be done with indexing, e.g., `points[0, 1]` retrieves the value at the specified index.\n",
    "  - A tensor's shape can be queried with `.shape`, indicating the size along each dimension.\n",
    "\n",
    "- **Views and Memory**:\n",
    "  - Accessing a subset of a tensor (e.g., a row or column) does not allocate new memory or copy data; it creates a new view on the existing data to improve efficiency.\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/638e0cd3-d1b4-4191-a6ef-cd89ce9229d9\" alt=\"listtensormemory Image\" width=\"800\" height=\"300\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d828de8",
   "metadata": {
    "id": "8d828de8",
    "origin_pos": 9
   },
   "source": [
    "[**A tensor represents a (possibly multidimensional) array of numerical values.**]\n",
    "In the one-dimensional case, i.e., when only one axis is needed for the data,\n",
    "a tensor is called a *vector*.\n",
    "With two axes, a tensor is called a *matrix*.\n",
    "With $k > 2$ axes, we drop the specialized names\n",
    "and just refer to the object as a $k^\\textrm{th}$-*order tensor*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "Am-cOEEWmF4H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1727004071785,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "Am-cOEEWmF4H",
    "outputId": "4e467633-94e7-446b-e7a1-22e47029a831"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80])\n",
      "Elements from 1 inclusive to 4 exclusive: tensor([20, 30, 40])\n",
      "Elements from 1 inclusive to the end: tensor([20, 30, 40, 50, 60, 70, 80])\n",
      "Elements from the start to 4 exclusive: tensor([10, 20, 30, 40])\n",
      "Elements from the start to one before the last: tensor([10, 20, 30, 40, 50, 60, 70])\n",
      "Elements from 1 to 4 exclusive, in steps of 2: tensor([20, 40])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a sample tensor for demonstration\n",
    "tensor = torch.tensor([10, 20, 30, 40, 50, 60, 70, 80])\n",
    "\n",
    "# Display the tensor\n",
    "print(\"Original tensor:\", tensor)\n",
    "\n",
    "# 1. All elements in the list from element 1 inclusive to element 4 exclusive\n",
    "sub_tensor1 = tensor[1:4]\n",
    "print(\"Elements from 1 inclusive to 4 exclusive:\", sub_tensor1)\n",
    "\n",
    "# 2. From element 1 inclusive to the end of the list\n",
    "sub_tensor2 = tensor[1:]\n",
    "print(\"Elements from 1 inclusive to the end:\", sub_tensor2)\n",
    "\n",
    "# 3. From the start of the list to element 4 exclusive\n",
    "sub_tensor3 = tensor[:4]\n",
    "print(\"Elements from the start to 4 exclusive:\", sub_tensor3)\n",
    "\n",
    "# 4. From the start of the list to one before the last element\n",
    "sub_tensor4 = tensor[:-1]\n",
    "print(\"Elements from the start to one before the last:\", sub_tensor4)\n",
    "\n",
    "# 5. From element 1 inclusive to element 4 exclusive, in steps of 2\n",
    "sub_tensor5 = tensor[1:4:2]\n",
    "print(\"Elements from 1 to 4 exclusive, in steps of 2:\", sub_tensor5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "Pmf2VmaCXRk_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 93,
     "status": "ok",
     "timestamp": 1727004071785,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "Pmf2VmaCXRk_",
    "outputId": "41bf09ff-8fdb-43f1-b1f6-439baa3785c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2D tensor:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "All rows after the first; implicitly all columns:\n",
      " tensor([[4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "All rows after the first; all columns:\n",
      " tensor([[4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "All rows after the first; first column:\n",
      " tensor([4, 7])\n",
      "\n",
      "Tensor with an added dimension (unsqueeze at position 0):\n",
      " tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 2D tensor for the following operations\n",
    "tensor_2d = torch.tensor([[1, 2, 3],\n",
    "                          [4, 5, 6],\n",
    "                          [7, 8, 9]])\n",
    "\n",
    "# Display the 2D tensor\n",
    "print(\"\\n2D tensor:\\n\", tensor_2d)\n",
    "\n",
    "# 6. All rows after the first; implicitly all columns\n",
    "sub_tensor6 = tensor_2d[1:]\n",
    "print(\"All rows after the first; implicitly all columns:\\n\", sub_tensor6)\n",
    "\n",
    "# 7. All rows after the first; all columns\n",
    "sub_tensor7 = tensor_2d[1:, :]\n",
    "print(\"All rows after the first; all columns:\\n\", sub_tensor7)\n",
    "\n",
    "# 8. All rows after the first; first column\n",
    "sub_tensor8 = tensor_2d[1:, 0]\n",
    "print(\"All rows after the first; first column:\\n\", sub_tensor8)\n",
    "\n",
    "# 9. Adds a dimension of size 1, just like unsqueeze\n",
    "# Adding a new dimension at position 0\n",
    "sub_tensor9 = tensor_2d.unsqueeze(0)\n",
    "print(\"\\nTensor with an added dimension (unsqueeze at position 0):\\n\", sub_tensor9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "WgPozn8MXn8t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1727004071785,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "WgPozn8MXn8t",
    "outputId": "e41c7060-c271-42de-c4e8-0f0331c032b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_tensor9.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a471639",
   "metadata": {
    "id": "1a471639",
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "PyTorch provides a variety of functions\n",
    "for creating new tensors\n",
    "prepopulated with values.\n",
    "For example, by invoking `arange(n)`,\n",
    "we can create a vector of evenly spaced values,\n",
    "starting at 0 (included)\n",
    "and ending at `n` (not included).\n",
    "By default, the interval size is $1$.\n",
    "Unless otherwise specified,\n",
    "new tensors are stored in main memory\n",
    "and designated for CPU-based computation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B3qx4JJWl8ds",
   "metadata": {
    "id": "B3qx4JJWl8ds"
   },
   "source": [
    "Specifying the numeric type with `dtype`\n",
    "\n",
    "PyTorch Tensor Data Types\n",
    "\n",
    "| `dtype` Argument          | Description                                 |\n",
    "|---------------------------|---------------------------------------------|\n",
    "| `torch.float32` or `torch.float`  | 32-bit floating-point                        |\n",
    "| `torch.float64` or `torch.double` | 64-bit double-precision floating-point       |\n",
    "| `torch.float16` or `torch.half`   | 16-bit half-precision floating-point          |\n",
    "| `torch.int8`               | Signed 8-bit integers                        |\n",
    "| `torch.uint8`              | Unsigned 8-bit integers                      |\n",
    "| `torch.int16` or `torch.short`    | Signed 16-bit integers                       |\n",
    "| `torch.int32` or `torch.int`      | Signed 32-bit integers                       |\n",
    "| `torch.int64` or `torch.long`     | Signed 64-bit integers                       |\n",
    "| `torch.bool`               | Boolean                                     |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b6aa30a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.056039Z",
     "iopub.status.busy": "2023-08-18T19:32:57.055276Z",
     "iopub.status.idle": "2023-08-18T19:32:57.089028Z",
     "shell.execute_reply": "2023-08-18T19:32:57.088195Z"
    },
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1727006408157,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "b6aa30a9",
    "origin_pos": 14,
    "outputId": "1852594b-eb3a-46f5-ffa5-58c0fe49de33",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12, dtype=torch.int64)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "mFW01QwYnjZf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1727004071785,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "mFW01QwYnjZf",
    "outputId": "1a5749d4-52f9-4306-f4e9-935e1120471d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int16"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.to(dtype=torch.short)\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vBwlj80kY9aN",
   "metadata": {
    "id": "vBwlj80kY9aN"
   },
   "source": [
    "**Summary Table**\n",
    "\n",
    "| Format    | Bits | Sign Bits | Exponent Bits | Mantissa Bits | Range                            | Precision                |\n",
    "|-----------|------|-----------|---------------|---------------|----------------------------------|--------------------------|\n",
    "| Float32   | 32   | 1         | 8             | 23            | Â±3.4 Ã— 10^38                      | ~7 decimal digits         |\n",
    "| Float64   | 64   | 1         | 11            | 52            | Â±1.8 Ã— 10^308                     | ~15-17 decimal digits     |\n",
    "| BFloat16  | 16   | 1         | 8             | 7             | Similar to Float32 (reduced precision) | ~3 decimal digits       |\n",
    "| TF32      | 19   | 1         | 8             | 10            | Similar to Float32                | Balanced for deep learning tasks |\n",
    "\n",
    "**Use Cases**\n",
    "\n",
    "- **Float32** is commonly used for general floating-point arithmetic in many applications.\n",
    "- **Float64** is used in scenarios requiring higher precision, such as scientific computations.\n",
    "- **BFloat16** and **TF32** are optimized for specific hardware (e.g., TPUs and NVIDIA Ampere GPUs) and are used in deep learning to balance performance and precision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "CKMraAGRYfrH",
   "metadata": {
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1727004071785,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "CKMraAGRYfrH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example of enabling mixed precision and TF32\n",
    "with torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "    # Perform tensor operations here with mixed precision\n",
    "    tensor = torch.randn((1024, 1024), device='cuda')\n",
    "    result = torch.matmul(tensor, tensor)\n",
    "\n",
    "# Check GPU architecture and enable TF32 if using Ampere or later\n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a12b5d8",
   "metadata": {
    "id": "1a12b5d8",
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "Each of these values is called\n",
    "an *element* of the tensor.\n",
    "The tensor `x` contains 12 elements.\n",
    "We can inspect the total number of elements\n",
    "in a tensor via its `numel` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "640cadaf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.093138Z",
     "iopub.status.busy": "2023-08-18T19:32:57.092473Z",
     "iopub.status.idle": "2023-08-18T19:32:57.098450Z",
     "shell.execute_reply": "2023-08-18T19:32:57.097452Z"
    },
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1727004071785,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "640cadaf",
    "origin_pos": 21,
    "outputId": "52196f21-b105-453b-b426-9536e5374269",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c7483",
   "metadata": {
    "id": "d50c7483",
    "origin_pos": 23
   },
   "source": [
    "(**We can access a tensor's *shape***)\n",
    "(the length along each axis)\n",
    "by inspecting its `shape` attribute.\n",
    "Because we are dealing with a vector here,\n",
    "the `shape` contains just a single element\n",
    "and is identical to the size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e0a9616",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.102194Z",
     "iopub.status.busy": "2023-08-18T19:32:57.101575Z",
     "iopub.status.idle": "2023-08-18T19:32:57.107424Z",
     "shell.execute_reply": "2023-08-18T19:32:57.106501Z"
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1727004071785,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "6e0a9616",
    "origin_pos": 24,
    "outputId": "3b28052f-3814-459a-d8f2-bad089073fb6",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i3uTuAb7u-OE",
   "metadata": {
    "id": "i3uTuAb7u-OE"
   },
   "source": [
    "Tensors: Scenic Views of Storage\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/ccb8c1c1-48b6-4da9-bed1-a9f76d393571\" alt=\"tensorview Image\" width=\"700\" height=\"400\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- **Storage Basics**:\n",
    "  - Tensors use contiguous memory blocks managed by `torch.Storage`.\n",
    "  - A `Storage` instance is a one-dimensional array of numerical data (e.g., `float32`, `int64`).\n",
    "\n",
    "- **Tensor as a View**:\n",
    "  - A PyTorch `Tensor` is a view into a `Storage` instance.\n",
    "  - Tensors index into storage using offsets and strides.\n",
    "\n",
    "- **Multiple Views**:\n",
    "  - Multiple tensors can reference the same `Storage`, even with different indexing.\n",
    "  - This allows for creating different tensor views (e.g., 1D vs. 2D) of the same underlying data.\n",
    "\n",
    "- **Efficiency**:\n",
    "  - The underlying memory is allocated once, making it efficient to create different tensor views.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "G1WlWqRT066N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1727004071785,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "G1WlWqRT066N",
    "outputId": "8e3e1bcd-518d-498e-d2cf-b318f40c2259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of storage: 96\n",
      "Storage contents: [2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "# Inspect storage\n",
    "storage = data.untyped_storage()\n",
    "print(\"Length of storage:\", len(storage))\n",
    "print(\"Storage contents:\", list(storage))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b589cdb",
   "metadata": {
    "id": "5b589cdb",
    "origin_pos": 48
   },
   "source": [
    "## Indexing and Slicing\n",
    "\n",
    "As with  Python lists,\n",
    "we can access tensor elements\n",
    "by indexing (starting with 0).\n",
    "To access an element based on its position\n",
    "relative to the end of the list,\n",
    "we can use negative indexing.\n",
    "Finally, we can access whole ranges of indices\n",
    "via slicing (e.g., `X[start:stop]`),\n",
    "where the returned value includes\n",
    "the first index (`start`) *but not the last* (`stop`).\n",
    "Finally, when only one index (or slice)\n",
    "is specified for a $k^\\textrm{th}$-order tensor,\n",
    "it is applied along axis 0.\n",
    "Thus, in the following code,\n",
    "[**`[-1]` selects the last row and `[1:3]`\n",
    "selects the second and third rows**].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "hpDIbVCGdoYl",
   "metadata": {
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1727004071785,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "hpDIbVCGdoYl"
   },
   "outputs": [],
   "source": [
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9049a53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.164537Z",
     "iopub.status.busy": "2023-08-18T19:32:57.163812Z",
     "iopub.status.idle": "2023-08-18T19:32:57.171699Z",
     "shell.execute_reply": "2023-08-18T19:32:57.170451Z"
    },
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1727004071786,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "d9049a53",
    "origin_pos": 49,
    "outputId": "0f82b974-1026-42e0-d7af-6a197cbcff06",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4, 3, 2, 1]),\n",
       " tensor([[1, 2, 3, 4],\n",
       "         [4, 3, 2, 1]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1], X[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5450673b",
   "metadata": {
    "id": "5450673b",
    "origin_pos": 50,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "Beyond reading them, (**we can also *write* elements of a matrix by specifying indices.**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9246619c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.176047Z",
     "iopub.status.busy": "2023-08-18T19:32:57.175685Z",
     "iopub.status.idle": "2023-08-18T19:32:57.182893Z",
     "shell.execute_reply": "2023-08-18T19:32:57.181890Z"
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1727004071786,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "9246619c",
    "origin_pos": 52,
    "outputId": "85337648-bb65-4814-c69a-c995c9ea68d2",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  1,  4,  3],\n",
       "        [ 1,  2, 17,  4],\n",
       "        [ 4,  3,  2,  1]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1, 2] = 17\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f06903",
   "metadata": {
    "id": "31f06903",
    "origin_pos": 55
   },
   "source": [
    "If we want [**to assign multiple elements the same value,\n",
    "we apply the indexing on the left-hand side\n",
    "of the assignment operation.**]\n",
    "For instance, `[:2, :]`  accesses\n",
    "the first and second rows,\n",
    "where `:` takes all the elements along axis 1 (column).\n",
    "While we discussed indexing for matrices,\n",
    "this also works for vectors\n",
    "and for tensors of more than two dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0532f024",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.186970Z",
     "iopub.status.busy": "2023-08-18T19:32:57.186270Z",
     "iopub.status.idle": "2023-08-18T19:32:57.193303Z",
     "shell.execute_reply": "2023-08-18T19:32:57.192338Z"
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1727004071786,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "0532f024",
    "origin_pos": 56,
    "outputId": "5fa4a083-968b-4894-cb80-d8c489151449",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12, 12, 12, 12],\n",
       "        [12, 12, 12, 12],\n",
       "        [ 4,  3,  2,  1]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2, :] = 12\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60413a",
   "metadata": {
    "id": "5c60413a",
    "origin_pos": 25
   },
   "source": [
    "We can [**change the shape of a tensor\n",
    "without altering its size or values**],\n",
    "by invoking `reshape`.\n",
    "For example, we can transform\n",
    "our vector `x` whose shape is (12,)\n",
    "to a matrix `X`  with shape (3, 4).\n",
    "This new tensor retains all elements\n",
    "but reconfigures them into a matrix.\n",
    "Notice that the elements of our vector\n",
    "are laid out one row at a time and thus\n",
    "`x[3] == X[0, 3]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4N4OX5zCb_7P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1727004071786,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "4N4OX5zCb_7P",
    "outputId": "48f95273-37ef-4934-952d-9c9d8965709b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=torch.int16)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6092207c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.111467Z",
     "iopub.status.busy": "2023-08-18T19:32:57.110749Z",
     "iopub.status.idle": "2023-08-18T19:32:57.117759Z",
     "shell.execute_reply": "2023-08-18T19:32:57.116917Z"
    },
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1727004071786,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "6092207c",
    "origin_pos": 26,
    "outputId": "45f25604-4889-46a5-901e-26bfbc4aa964",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]], dtype=torch.int16)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = x.reshape(3, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2e1706",
   "metadata": {
    "id": "2d2e1706",
    "origin_pos": 28
   },
   "source": [
    "Note that specifying every shape component\n",
    "to `reshape` is redundant.\n",
    "Because we already know our tensor's size,\n",
    "we can work out one component of the shape given the rest.\n",
    "For example, given a tensor of size $n$\n",
    "and target shape ($h$, $w$),\n",
    "we know that $w = n/h$.\n",
    "To automatically infer one component of the shape,\n",
    "we can place a `-1` for the shape component\n",
    "that should be inferred automatically.\n",
    "In our case, instead of calling `x.reshape(3, 4)`,\n",
    "we could have equivalently called `x.reshape(-1, 4)` or `x.reshape(3, -1)`.\n",
    "\n",
    "Practitioners often need to work with tensors\n",
    "initialized to contain all 0s or 1s.\n",
    "[**We can construct a tensor with all elements set to 0**] (~~or one~~)\n",
    "and a shape of (2, 3, 4) via the `zeros` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "383cafca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.122018Z",
     "iopub.status.busy": "2023-08-18T19:32:57.121194Z",
     "iopub.status.idle": "2023-08-18T19:32:57.128294Z",
     "shell.execute_reply": "2023-08-18T19:32:57.127285Z"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1727004071786,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "383cafca",
    "origin_pos": 30,
    "outputId": "249afbc9-8d0e-4362-efb1-8c9d8b1fedcb",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e967d02",
   "metadata": {
    "id": "1e967d02",
    "origin_pos": 33
   },
   "source": [
    "Similarly, we can create a tensor\n",
    "with all 1s by invoking `ones`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ea249d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.132534Z",
     "iopub.status.busy": "2023-08-18T19:32:57.131716Z",
     "iopub.status.idle": "2023-08-18T19:32:57.139029Z",
     "shell.execute_reply": "2023-08-18T19:32:57.138135Z"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1727004071786,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "0ea249d4",
    "origin_pos": 35,
    "outputId": "eb3ad250-e395-4a7b-aea5-51e41cc41f5c",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0615f2d6",
   "metadata": {
    "id": "0615f2d6",
    "origin_pos": 38
   },
   "source": [
    "We often wish to\n",
    "[**sample each element randomly (and independently)**]\n",
    "from a given probability distribution.\n",
    "For example, the parameters of neural networks\n",
    "are often initialized randomly.\n",
    "The following snippet creates a tensor\n",
    "with elements drawn from\n",
    "a standard Gaussian (normal) distribution\n",
    "with mean 0 and standard deviation 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2254595d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.143051Z",
     "iopub.status.busy": "2023-08-18T19:32:57.142388Z",
     "iopub.status.idle": "2023-08-18T19:32:57.149695Z",
     "shell.execute_reply": "2023-08-18T19:32:57.148813Z"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1727004071786,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "2254595d",
    "origin_pos": 40,
    "outputId": "af61b6bd-30f9-41e8-ea90-4fab608f0bfe",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0460,  1.2824, -0.8506, -0.5494],\n",
       "        [ 0.2723,  0.1910,  1.1940,  0.8288],\n",
       "        [ 0.7304, -0.0231, -1.7699,  0.9374]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35eda39",
   "metadata": {
    "id": "d35eda39",
    "origin_pos": 43
   },
   "source": [
    "Finally, we can construct tensors by\n",
    "[**supplying the exact values for each element**]\n",
    "by supplying (possibly nested) Python list(s)\n",
    "containing numerical literals.\n",
    "Here, we construct a matrix with a list of lists,\n",
    "where the outermost list corresponds to axis 0,\n",
    "and the inner list corresponds to axis 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b26863d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.153567Z",
     "iopub.status.busy": "2023-08-18T19:32:57.153222Z",
     "iopub.status.idle": "2023-08-18T19:32:57.160436Z",
     "shell.execute_reply": "2023-08-18T19:32:57.159548Z"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1727004071786,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "b26863d8",
    "origin_pos": 45,
    "outputId": "2a957f40-5daa-40eb-b914-c7e1f664ab6b",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4, 3],\n",
       "        [1, 2, 3, 4],\n",
       "        [4, 3, 2, 1]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cdce97",
   "metadata": {
    "id": "02cdce97",
    "origin_pos": 59
   },
   "source": [
    "## Operations\n",
    "\n",
    "- **Mathematical Operations**:\n",
    "  - Tensors can be manipulated with various operations.\n",
    "  - **Elementwise Operations** are a key type, applying scalar operations to each tensor element.\n",
    "\n",
    "- **Elementwise Functions**:\n",
    "  - Unary functions map a scalar to a scalar (e.g., $e^x$).\n",
    "  - Apply elementwise to each tensor element.\n",
    "\n",
    "- **Binary Operations**:\n",
    "  - For functions with two tensor inputs, apply the operation to each pair of corresponding elements.\n",
    "\n",
    "- **Notation**:\n",
    "  - Unary operators: $f: \\mathbb{R} \\rightarrow \\mathbb{R}$, mapping real numbers to real numbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YtuDnqwWozVb",
   "metadata": {
    "id": "YtuDnqwWozVb"
   },
   "source": [
    "PyTorch Tensor Operations\n",
    "\n",
    "| Operation Group                          | Description                                             | Examples                   |\n",
    "|------------------------------------------|---------------------------------------------------------|----------------------------|\n",
    "| **Creation ops**                        | Functions for constructing tensors                     | `ones`, `from_numpy`       |\n",
    "| **Indexing, slicing, joining, mutating ops** | Functions for modifying tensor shape, stride, or content | `transpose`                |\n",
    "| **Math ops**                            | Functions for tensor computations                      |                            |\n",
    "| - Pointwise ops                         | Apply a function to each element independently         | `abs`, `cos`               |\n",
    "| - Reduction ops                         | Compute aggregate values across tensors                | `mean`, `std`, `norm`      |\n",
    "| - Comparison ops                        | Evaluate numerical predicates over tensors             | `equal`, `max`             |\n",
    "| - Spectral ops                          | Transform and operate in the frequency domain          | `stft`, `hamming_window`   |\n",
    "| - Other operations                      | Special functions for vectors and matrices             | `cross`, `trace`           |\n",
    "| - BLAS and LAPACK operations            | Scalar, vector, and matrix operations following BLAS    |                            |\n",
    "| **Random sampling**                     | Generate values from probability distributions          | `randn`, `normal`          |\n",
    "| **Serialization**                       | Save and load tensors                                  | `load`, `save`             |\n",
    "| **Parallelism**                         | Control number of threads for parallel CPU execution   | `set_num_threads`    |\n",
    "\n",
    "The online docs provide exhaustive and well organized example (http://pytorch.org/docs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ko_OSZBRoNVD",
   "metadata": {
    "id": "Ko_OSZBRoNVD"
   },
   "source": [
    "When mixing input types in operations, the inputs are converted to the larger type\n",
    "automatically. Thus, if we want 32-bit computation, we need to make sure all our\n",
    "inputs are (at most) 32-bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6dd6724c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.197301Z",
     "iopub.status.busy": "2023-08-18T19:32:57.196599Z",
     "iopub.status.idle": "2023-08-18T19:32:57.206136Z",
     "shell.execute_reply": "2023-08-18T19:32:57.205188Z"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1727004071786,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "6dd6724c",
    "origin_pos": 61,
    "outputId": "86c273ff-3698-4aff-d74c-bef27ebef829",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
       "        4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03, 2.2026e+04, 5.9874e+04])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70f353f",
   "metadata": {
    "id": "b70f353f",
    "origin_pos": 64
   },
   "source": [
    "Binary Scalar Operators\n",
    "\n",
    "- **Binary Operators**:\n",
    "  - Map pairs of real numbers to a single real number.\n",
    "  - Notation: $f: \\mathbb{R}, \\mathbb{R} \\rightarrow \\mathbb{R}$.\n",
    "\n",
    "- **Elementwise Binary Operation**:\n",
    "  - Given two vectors $\\mathbf{u}$ and $\\mathbf{v}$ of the same shape, and a binary operator $f$:\n",
    "    - Produce a vector $\\mathbf{c} = F(\\mathbf{u}, \\mathbf{v})$.\n",
    "    - Each element $c_i$ is computed as $c_i \\gets f(u_i, v_i)$, where $c_i$, $u_i$, and $v_i$ are the $i$-th elements of $\\mathbf{c}$, $\\mathbf{u}$, and $\\mathbf{v}$, respectively.\n",
    "\n",
    "- **Function Lifting**:\n",
    "  - Scalar function $f$ is \"lifted\" to operate elementwise on vectors.\n",
    "  - Notation: $F: \\mathbb{R}^d, \\mathbb{R}^d \\rightarrow \\mathbb{R}^d$, extending the scalar function to vectors.\n",
    "\n",
    "- **Standard Arithmetic Operators**:\n",
    "  - Common operations like addition (`+`), subtraction (`-`), multiplication (`*`), division (`/`), and exponentiation (`**`) are lifted to handle elementwise operations on tensors of the same shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89bc996d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.210417Z",
     "iopub.status.busy": "2023-08-18T19:32:57.209741Z",
     "iopub.status.idle": "2023-08-18T19:32:57.219298Z",
     "shell.execute_reply": "2023-08-18T19:32:57.218318Z"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1727004071786,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "89bc996d",
    "origin_pos": 66,
    "outputId": "b06e6e71-9f75-49f8-b0c6-7e4c24d5880f",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1.,  4., 16., 64.]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2, 4, 8])\n",
    "y = torch.tensor([2, 2, 2, 2])\n",
    "x + y, x - y, x * y, x / y, x ** y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ae1d38",
   "metadata": {
    "id": "04ae1d38",
    "origin_pos": 69
   },
   "source": [
    "Tensor Operations\n",
    "\n",
    "- **Elementwise Computations**:\n",
    "  - Perform operations like addition and multiplication on corresponding elements of tensors.\n",
    "  - For details on linear algebraic operations (e.g., dot products, matrix multiplications), see :numref:`sec_linear-algebra`.\n",
    "\n",
    "- **Concatenation**:\n",
    "  - Combine multiple tensors by stacking them along a specified axis.\n",
    "  - Provide a list of tensors and specify the axis for concatenation.\n",
    "  - Example: Concatenating two matrices along different axes:\n",
    "    - **Along rows (axis 0)**: The resulting tensor's axis-0 length is the sum of the input tensors' axis-0 lengths.\n",
    "    - **Along columns (axis 1)**: The resulting tensor's axis-1 length is the sum of the input tensors' axis-1 lengths.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "43aa9012",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.223534Z",
     "iopub.status.busy": "2023-08-18T19:32:57.222711Z",
     "iopub.status.idle": "2023-08-18T19:32:57.233166Z",
     "shell.execute_reply": "2023-08-18T19:32:57.232145Z"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1727004071786,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "43aa9012",
    "origin_pos": 71,
    "outputId": "dc520047-00d0-4b4f-a99c-a234f103185e",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "\n",
    "#   X = ([[ 0.,  1.,  2.,  3.],\n",
    "#         [ 4.,  5.,  6.,  7.],\n",
    "#         [ 8.,  9., 10., 11.]])\n",
    "\n",
    "Y = torch.tensor([[2.0, 1, 4, 3],\n",
    "                  [1  , 2, 3, 4],\n",
    "                  [4  , 3, 2, 1]])\n",
    "\n",
    "torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346adeed",
   "metadata": {
    "id": "346adeed",
    "origin_pos": 74
   },
   "source": [
    "Sometimes, we want to\n",
    "[**construct a binary tensor via *logical statements*.**]\n",
    "Take `X == Y` as an example.\n",
    "For each position `i, j`, if `X[i, j]` and `Y[i, j]` are equal,\n",
    "then the corresponding entry in the result takes value `1`,\n",
    "otherwise it takes value `0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91d39e58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.237276Z",
     "iopub.status.busy": "2023-08-18T19:32:57.236485Z",
     "iopub.status.idle": "2023-08-18T19:32:57.243133Z",
     "shell.execute_reply": "2023-08-18T19:32:57.242117Z"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1727004071786,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "91d39e58",
    "origin_pos": 75,
    "outputId": "182e008c-7066-4089-f6cc-e7cc29f23975",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00448db5",
   "metadata": {
    "id": "00448db5",
    "origin_pos": 76
   },
   "source": [
    "[**Summing all the elements in the tensor**] yields a tensor with only one element.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "080b0125",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.247142Z",
     "iopub.status.busy": "2023-08-18T19:32:57.246480Z",
     "iopub.status.idle": "2023-08-18T19:32:57.253117Z",
     "shell.execute_reply": "2023-08-18T19:32:57.252212Z"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1727004071787,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "080b0125",
    "origin_pos": 77,
    "outputId": "cf14db1c-a974-494c-d3bc-adbf7cbd9a3c",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UW6ePH3-_IUP",
   "metadata": {
    "id": "UW6ePH3-_IUP"
   },
   "source": [
    "Tensor metadata: Size, offset, and stride\n",
    "\n",
    "\n",
    "- **Transposing**:\n",
    "  - `points.t()` transposes a tensor without copying data.\n",
    "  - Transposing changes strides but uses the same storage.\n",
    "\n",
    "- **Storage and Strides**:\n",
    "  - Transposed tensors share the same storage as the original.\n",
    "  - Example: `points.stride()` vs. `points_t.stride()`\n",
    "\n",
    "- **Higher-Dimensional Transposing**:\n",
    "  - Apply `transpose(dim1, dim2)` to higher-dimensional tensors.\n",
    "\n",
    "- **Contiguous Tensors**:\n",
    "  - Contiguous tensors store elements sequentially.\n",
    "  - Use `tensor.is_contiguous()` to check and `tensor.contiguous()` to ensure contiguity.\n",
    "\n",
    "- **Moving to GPU**:\n",
    "  - Tensors can be moved to a GPU for faster computations using GPU-specific routines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JhoI4zIzBOyY",
   "metadata": {
    "id": "JhoI4zIzBOyY"
   },
   "source": [
    "Contiguity and Tensor Views\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/c50a0940-f8c4-424e-b293-fcd6c28f11b1\" alt=\"tesnorview Image\" width=\"700\" height=\"400\">\n",
    "\n",
    "Relationship between a tensorâ€™s offset, size, and stride. Here the tensor is a view\n",
    "of a larger storage, like one that might have been allocated when creating a larger tensor.\n",
    "Essentially, strides help in navigating through the tensorâ€™s data in memory.\n",
    "\n",
    "- **Tensor View**:\n",
    "  - Provides a different shape or indexing perspective on the same data.\n",
    "  - Created by operations like slicing or transposing.\n",
    "\n",
    "- **Contiguous Tensor**:\n",
    "  - Data is stored in a single, linear block of memory.\n",
    "  - Efficient for memory access.\n",
    "\n",
    "- **Non-Contiguous Tensor**:\n",
    "  - Data is not in a single block, often due to stride changes.\n",
    "\n",
    "- **Views and Contiguity**:\n",
    "  - Views can be contiguous or non-contiguous based on data access.\n",
    "  - Non-contiguous views might need conversion for certain operations.\n",
    "\n",
    "- **Making Contiguous**:\n",
    "  - Use `tensor.contiguous()` to create a contiguous version of a non-contiguous tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a78360",
   "metadata": {
    "id": "e6a78360",
    "origin_pos": 79
   },
   "source": [
    "## Broadcasting\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/fd4078db-00ba-4d63-be80-103a149bc1e4\" alt=\"tensorbroadcast Image\" width=\"700\" height=\"600\">\n",
    "\n",
    "- **Elementwise Operations**:\n",
    "  - Typically performed on tensors of the same shape.\n",
    "\n",
    "- **Broadcasting Mechanism**:\n",
    "  - **Step 1**: Expand tensors with shape differences by copying elements along axes of length 1 to match shapes.\n",
    "  - **Step 2**: Perform elementwise operations on the expanded tensors.\n",
    "\n",
    "- **Purpose**: Allows elementwise operations on tensors with different shapes by aligning them through expansion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iVDQ5ssuiYME",
   "metadata": {
    "id": "iVDQ5ssuiYME"
   },
   "source": [
    "\n",
    "**Key Scenarios and Benefits of Broadcasting in Neural Networks**\n",
    "\n",
    "| **Scenario**             | **Usage**                                                | **Benefit**                                              |\n",
    "|--------------------------|----------------------------------------------------------|----------------------------------------------------------|\n",
    "| **Elementwise Operations** | Adding biases to activations, applying activation functions | Simplifies operations by expanding shapes automatically, avoiding manual reshaping |\n",
    "| **Normalization**         | Normalizing data (e.g., batch normalization)             | Efficiently applies normalization statistics across a batch without explicit reshaping |\n",
    "| **Loss Functions**        | Comparing predictions to ground truths (e.g., cross-entropy loss) | Handles tensors of different shapes for loss calculations, simplifying the implementation |\n",
    "| **Convolution Operations** | Applying convolutional kernels to different parts or channels | Facilitates efficient application of kernels across various dimensions using broadcasting |\n",
    "| **Parameter Updates**     | Updating weights and biases during backpropagation       | Ensures gradients are applied correctly to parameters of different shapes |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "be37d2de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.256932Z",
     "iopub.status.busy": "2023-08-18T19:32:57.256264Z",
     "iopub.status.idle": "2023-08-18T19:32:57.263823Z",
     "shell.execute_reply": "2023-08-18T19:32:57.262881Z"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1727004071787,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "be37d2de",
    "origin_pos": 81,
    "outputId": "1b862f45-a53e-4484-b2e3-1a6adf1e2607",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e8410",
   "metadata": {
    "id": "6c7e8410",
    "origin_pos": 84
   },
   "source": [
    "Since `a` and `b` are $3\\times1$\n",
    "and $1\\times2$ matrices, respectively,\n",
    "their shapes do not match up.\n",
    "Broadcasting produces a larger $3\\times2$ matrix\n",
    "by replicating matrix `a` along the columns\n",
    "and matrix `b` along the rows\n",
    "before adding them elementwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f62e827",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.267856Z",
     "iopub.status.busy": "2023-08-18T19:32:57.267172Z",
     "iopub.status.idle": "2023-08-18T19:32:57.273497Z",
     "shell.execute_reply": "2023-08-18T19:32:57.272587Z"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1727004071787,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "9f62e827",
    "origin_pos": 85,
    "outputId": "87ed52d0-2c78-4a73-ad46-fd53ef2320b6",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d68609",
   "metadata": {
    "id": "c5d68609",
    "origin_pos": 86
   },
   "source": [
    "## Saving Memory\n",
    "\n",
    "- **Memory Allocation**:\n",
    "  - Operations may allocate new memory for results.\n",
    "  - Example: `Y = X + Y` creates new memory for the result.\n",
    "\n",
    "- **Memory Address**:\n",
    "  - Use Python's `id()` function to check memory addresses.\n",
    "  - After `Y = Y + X`, `id(Y)` changes, indicating `Y` now points to new memory.\n",
    "\n",
    "- **Explanation**:\n",
    "  - Python evaluates `Y + X`, allocates new memory, and updates `Y` to point to this new location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "754a7433",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.277697Z",
     "iopub.status.busy": "2023-08-18T19:32:57.277047Z",
     "iopub.status.idle": "2023-08-18T19:32:57.283549Z",
     "shell.execute_reply": "2023-08-18T19:32:57.282613Z"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1727004071787,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "754a7433",
    "origin_pos": 87,
    "outputId": "24f52be4-0cb0-4aa7-b70a-b42608433cdc",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(Y)\n",
    "Y = Y + X\n",
    "id(Y) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322d26f5",
   "metadata": {
    "id": "322d26f5",
    "origin_pos": 88
   },
   "source": [
    "Issues with Unnecessary Memory Allocation\n",
    "\n",
    "- **Memory Allocation Concerns**:\n",
    "  - Frequent allocation of new memory can be inefficient.\n",
    "  - In machine learning, large models update parameters rapidly, making in-place updates desirable.\n",
    "\n",
    "- **In-Place Updates**:\n",
    "  - Reduces memory usage by updating existing data rather than allocating new memory.\n",
    "  - Essential for handling large parameters efficiently.\n",
    "\n",
    "- **Multiple References**:\n",
    "  - Variables may point to the same parameters.\n",
    "  - Without in-place updates, managing these references can be tricky, risking memory leaks or stale data.\n",
    "\n",
    "- **Best Practice**:\n",
    "  - Prefer in-place operations to avoid unnecessary memory allocation and ensure consistent updates across references.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82880947",
   "metadata": {
    "id": "82880947",
    "origin_pos": 89,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "Performing In-Place Operations\n",
    "\n",
    "- **In-Place Operations**:\n",
    "  - Assign results directly to an existing array using slice notation: `Y[:] = <expression>`.\n",
    "\n",
    "- **Example**:\n",
    "  - Overwrite values of tensor `Z` with the same shape as `Y` using `zeros_like`.\n",
    "\n",
    "- **Benefit**:\n",
    "  - Efficiently updates the contents of an existing tensor without allocating new memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4d62609",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.287695Z",
     "iopub.status.busy": "2023-08-18T19:32:57.286964Z",
     "iopub.status.idle": "2023-08-18T19:32:57.293078Z",
     "shell.execute_reply": "2023-08-18T19:32:57.292048Z"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1727004071788,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "c4d62609",
    "origin_pos": 92,
    "outputId": "3195c877-46bc-4d23-9ae5-de6e5b78d477",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(Z): 134659203321984\n",
      "id(Z): 134659203321984\n"
     ]
    }
   ],
   "source": [
    "Z = torch.zeros_like(Y)\n",
    "print('id(Z):', id(Z))\n",
    "Z[:] = X + Y\n",
    "print('id(Z):', id(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d745b125",
   "metadata": {
    "id": "d745b125",
    "origin_pos": 95,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[**If the value of `X` is not reused in subsequent computations,\n",
    "we can also use `X[:] = X + Y` or `X += Y`\n",
    "to reduce the memory overhead of the operation.**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b8c13447",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.296911Z",
     "iopub.status.busy": "2023-08-18T19:32:57.296361Z",
     "iopub.status.idle": "2023-08-18T19:32:57.302754Z",
     "shell.execute_reply": "2023-08-18T19:32:57.301805Z"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1727004071788,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "b8c13447",
    "origin_pos": 97,
    "outputId": "1927f5a9-0030-40fb-a6f3-afa2299eb655",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(X)\n",
    "X += Y\n",
    "id(X) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f887dd",
   "metadata": {
    "id": "b5f887dd",
    "origin_pos": 99
   },
   "source": [
    "## Conversion to Other Python Objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd057d04",
   "metadata": {
    "id": "cd057d04",
    "origin_pos": 101,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[**Converting to a NumPy tensor (`ndarray`)**], or vice versa, is easy.\n",
    "The torch tensor and NumPy array\n",
    "will share their underlying memory,\n",
    "and changing one through an in-place operation\n",
    "will also change the other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "576963aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.306812Z",
     "iopub.status.busy": "2023-08-18T19:32:57.306088Z",
     "iopub.status.idle": "2023-08-18T19:32:57.312356Z",
     "shell.execute_reply": "2023-08-18T19:32:57.311478Z"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1727004071788,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "576963aa",
    "origin_pos": 103,
    "outputId": "eb5dc88f-1ba6-4da3-f6db-3ced96f1d7b1",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = X.numpy()\n",
    "B = torch.from_numpy(A)\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2def017",
   "metadata": {
    "id": "b2def017",
    "origin_pos": 106
   },
   "source": [
    "To (**convert a size-1 tensor to a Python scalar**),\n",
    "we can invoke the `item` function or Python's built-in functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "388c5252",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.316471Z",
     "iopub.status.busy": "2023-08-18T19:32:57.315825Z",
     "iopub.status.idle": "2023-08-18T19:32:57.322867Z",
     "shell.execute_reply": "2023-08-18T19:32:57.322007Z"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1727004071788,
     "user": {
      "displayName": "Abdalrahman Ibrahim",
      "userId": "07976270546137220456"
     },
     "user_tz": -120
    },
    "id": "388c5252",
    "origin_pos": 108,
    "outputId": "623b91f2-845f-4f6b-cb7f-a9195b824f6e",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9373077d",
   "metadata": {
    "id": "9373077d",
    "origin_pos": 111
   },
   "source": [
    "## Summary\n",
    "\n",
    "The tensor class is the main interface for storing and manipulating data in deep learning libraries.\n",
    "Tensors provide a variety of functionalities including construction routines; indexing and slicing; basic mathematics operations; broadcasting; memory-efficient assignment; and conversion to and from other Python objects.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/d2l-ai/d2l-pytorch-colab/blob/master/chapter_preliminaries/ndarray.ipynb",
     "timestamp": 1723194965934
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
